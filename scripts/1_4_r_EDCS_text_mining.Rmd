---
title: "Text mining of EDCS"
author: "Petra Hermankova"
date: "22/12/2020"
output:
  html_document:
    theme: united
    toc: yes
    toc_float: true
    number_sections: true
    toc_depth: 2
    df_print: paged
---

```{r setup, include=FALSE, echo=FALSE}
require("knitr")
opts_knit$set(root.dir = "/home/petra/Github/ClaussSlaby_ETL/")

library(tidyverse)
library(jsonlite)
library(data.table)
library(leaflet)
library(sdam)
```

## Loading data
Load the dataset, if you have Sciencedata.dk credentials

```{r, echo=FALSE}
mycred_secret<- readLines("~/mysecret.txt")
```

```{r, loading data}
resp = request("EDCS_text_cleaned_2020-12-29.json", path="/sharingin/648597@au.dk/SDAM_root/SDAM_data/EDCS", method="GET", cred=mycred_secret)
```

```{r, echo=FALSE}
remove(mycred_secret)
```

OR of you don't have Sciencedata credentials: 
```{r, loading data public, eval=FALSE} 
#The folder still needs to made public by owner (Vojtech Kase)
resp = request("EDCS_text_cleaned_2020-12-29.json", path="/sharingin/648597@au.dk/SDAM_root/SDAM_data/EDCS", method="GET")
```

Make a list and tibble from the downloaded dataset
```{r}
list_json <- jsonlite::fromJSON("output/EDCS_text_cleaned_2020-12-29.json")
EDCS = as_tibble(list_json)
```

# Text mining using udpipe package
source: https://cran.r-project.org/web/packages/udpipe/vignettes/udpipe-annotation.html#udpipe_-_general

## Download model for given language
```{r}
library(udpipe)
#dl <- udpipe_download_model(language = "ancient_greek")
dl <- udpipe_download_model(language = "latin")
str(dl)
```

## Give the full path to the model and load it to R
```{r}
# udmodel_anc_greek <- udpipe_load_model(file = "ancient_greek-perseus-ud-2.4-190531.udpipe")
udmodel_latin <- udpipe_load_model(file = "latin-perseus-ud-2.4-190531.udpipe")
```

## Anotate the text using UDpipe
```{r}
udpipe_text <- as.data.frame(udpipe_annotate(udmodel_latin, x = EDCS$clean_text_interpretive_word))
str(udpipe_text)
```

## Overview of linguistic word categories
```{r}
table(udpipe_text$upos)
```

```{r}
nouns <- udpipe_text %>% 
  filter(udpipe_text$upos == "NOUN") 
```

```{r}
verbs <- udpipe_text %>% 
  filter(udpipe_text$upos == "VERB") 
```

```{r}
punctuation <- udpipe_text %>% 
  filter(udpipe_text$upos == "PUNCT") 
```

```{r}
problematic <- udpipe_text %>% 
  filter(udpipe_text$upos == "X") 
```

## The most frequent of all word lemmata
```{r}
udpipe_text %>% 
  count(lemma, sort = TRUE) %>%
  filter(n > 1000) %>% 
  mutate(lemma = reorder(lemma, n)) %>%
  print()
```

## The most frequent of nouns lemmata
```{r}
nouns %>% 
  count(lemma, sort = TRUE) %>%
  filter(n > 1000) %>% 
  mutate(lemma = reorder(lemma, n)) %>%
  print()
```

```{r}
verbs %>% 
  count(lemma, sort = TRUE) %>%
  filter(n > 1000) %>% 
  mutate(lemma = reorder(lemma, n)) %>%
  print()
```

```{r}
punctuation %>% 
  count(lemma, sort = TRUE) %>%
  filter(n > 10) %>% 
  mutate(lemma = reorder(lemma, n)) %>%
  print()
```


## Join the entire dataset with the NLP UD pipe output
```{r}



tail(udpipe_text)
udpipe_text <- udpipe_text %>% 
  mutate(insc_id = (as.numeric(str_replace(doc_id, pattern = "doc", replacement = ""))))
EDCS$doc_id <- 1:nrow(EDCS)

full_appended <- left_join(EDCS, udpipe_text, by = c("doc_id" = "insc_id"))
head(full_appended)
```


```{r}
save(full_appended, file="output/EDCS_lemmatized_2020-12-29.Rdata")
```

# Save to Sciencedata
```{r}
EDCS_lemmatized_json <- jsonlite::toJSON(full_appended, auto_unbox = TRUE)
mycred_secret<- readLines("~/mysecret.txt")
write(EDCS_lemmatized_json, file="output/EDCS_text_lemmatized_udpipe_2020-12-29.json")
request("output/EDCS_text_lemmatized_udpipe_2020-12-29.json", path="/sharingout/648597@au.dk/SDAM_root/SDAM_data/EDCS/",
        method="PUT", cred=c(mycred_secret[1], mycred_secret[2]))
```


# Search for Road-related inscription

## Defining road related vocabulary
```{r}
road_vocabulary1 <- c("via", "pons", "mutatio", "mansio", "caput viae", "miliarium", "millia passuum", "passus", "carpentum", "porta", "vicus", "clivus", "semita", "angiportus", "scala", "gradus", "gressus", "incessus", "leuga", "tabellarium", "tabelarium", "itinerarium", "annona", "actus", "cursus publicus", "vehiculatio", "vehiculum", "iter", "iumentum", "Via publica", "Via privata", "Via vicinalis", "Via terrena", "viam munire", "viam fecit", "viam refecit", "viam restituit", "curator viarum", "compitum", "deverticulum", "diverticulum", "civitas", "viator", "arcus", "statio", "terminus", "lares viales", "lares compitales", "Redicolus", "Ianus")
road_vocabulary2 <- c("παροδεῖτα")
```

## Searching for predefined vocabulary in lemmata
```{r}
full_appended %>%
  count(lemma, sort = TRUE) %>%
  filter(lemma %in% road_vocabulary1) %>% 
  print()
```

```{r}
full_appended %>%
  filter(token == "viator") %>%
  count()
```

```{r}
full_appended %>%
  filter(lemma == "viator") %>%
  count()
```

```{r}
length(unique(str_subset(full_appended$clean_text_interpretive_word, "viator"))) 
```

```{r}
full_appended %>% 
  filter(full_appended$inscription == str_subset(full_appended$inscription, "viator viator quod tu"))
```



### Separating the subdataset containing the predefined vocabulary
```{r}
road_text <- full_appended %>%
  filter(lemma %in% road_vocabulary1) %>% 
  print()
```

### From what province some road related inscriptions
```{r}
road_text %>% 
  count(province, sort=TRUE)
```

### What are the most common words (lemma and token)
```{r}
road_text %>% 
  count(lemma, token, sort=TRUE)
```

### How many unique inscriptions there are
```{r}
length(unique(road_text$doc_id))
```

### Select only the text of inscriptions once
```{r}
road_unique<- road_text %>% distinct(doc_id, .keep_all = TRUE)
```


```{r}
library(leaflet)

road_unique$Longitude <- as.numeric(road_unique$Longitude)
road_unique$Latitude <- as.numeric (road_unique$Latitude)

map_road_insc <-leaflet(width="100%") %>%
  addProviderTiles("Stamen.Watercolor")%>% # Add CartoDB map tiles
  addCircles(lng = road_unique$Longitude, 
             lat = road_unique$Latitude, radius = 10, fill = TRUE, color= , fillColor = road_unique$province,
             popup = paste0("<b> InscriptionID: </b>", road_unique$`EDCS-ID` , 
                            "<br><b> Ancient findspot: </b>", road_unique$place,
                             "<br><b> Type of inscription: </b>", road_unique$status,
                              "<br><b> Material: </b>", road_unique$Material,
                              "<br><b> Not before (date): </b>", road_unique$`dating from`,
                              "<br><b> Not after (date): </b>", road_unique$`dating to`,
                                "<br><b> Text: </b>", road_unique$clean_text_interpretive_word),
) %>% 
addLegend(position = "topright",
  colors = c("Blue"),
  labels = c("Inscriptions"), opacity = 1,
  title = "Position of all road realted inscriptions in EDCS" 
)
map_road_insc


```
# Saving to Sciencedata
```{r}
EDCS_cleaned_json <- jsonlite::toJSON(full_appended, auto_unbox = TRUE)
mycred_secret<- readLines("~/mysecret.txt")
write(EDCS_cleaned_json, file="output/EDCS_text_lemmatized_udpipe_2020-12-22.json")
request("output/EDCS_text_lemmatized_udpipe_2020-12-22.json", path="/sharingout/648597@au.dk/SDAM_root/SDAM_data/EDCS/",
        method="PUT", cred=c(mycred_secret[1], mycred_secret[2]))
```

# Remove local copy of the json and the credential before submitting to GitHub
```{r}
file.remove("./EDCS_text_lemmatized_udpipe_2020-12-22.json")
remove(mycred_secret)
```
