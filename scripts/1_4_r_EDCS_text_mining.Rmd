---
title: "Text mining of EDCS"
author: "Petra Hermankova"
date: "22/12/2020"
output:
  html_document:
    theme: united
    toc: yes
    toc_float: true
    number_sections: true
    toc_depth: 2
    df_print: paged
---

```{r setup, include=FALSE, echo=FALSE}
require("knitr")
opts_knit$set(root.dir = "/home/petra/Github/EDCS_ETL/")

library(tidyverse)
library(jsonlite)
library(data.table)
library(leaflet)
library(sdam)
```

## Loading data
Load the dataset, if you have Sciencedata.dk credentials

```{r, echo=FALSE}
mycred_secret<- readLines("~/mysecret.txt")
```

```{r, loading data}
resp = request("EDCS_text_cleaned_2021-01-21.json", path="/sharingin/648597@au.dk/SDAM_root/SDAM_data/EDCS/public", method="GET", cred=mycred_secret)
```

```{r, echo=FALSE}
remove(mycred_secret)
```

OR of you don't have Sciencedata credentials:
```{r, loading data public, eval=FALSE}
#The folder still needs to made public by owner (Vojtech Kase)
resp = request("EDCS_text_cleaned_2021-01-21.json", path="/shared/1f5f56d09903fe259c0906add8b3a55e", method="GET")
```

Make a list and tibble from the downloaded dataset
```{r}
list_json <- jsonlite::fromJSON(resp)
EDCS = as_tibble(list_json)
```

# Text mining using udpipe package
source: https://cran.r-project.org/web/packages/udpipe/vignettes/udpipe-annotation.html#udpipe_-_general

## Download model for given language
```{r}
#dl <- udpipe_download_model(language = "ancient_greek")


dl <- udpipe_download_model(udpipe_model_repo = "jwijffels/udpipe.models.ud.2.5" , language = "latin-proiel", model_dir = "../data/") # latin-proiel model

dl2 <- udpipe_download_model(udpipe_model_repo = "jwijffels/udpipe.models.ud.2.5", language = "latin-perseus", model_dir = "../data/") # latin-perseus model

```

## Give the full path to the model and load it to R
```{r}
# udmodel_anc_greek <- udpipe_load_model(file = "ancient_greek-perseus-ud-2.4-190531.udpipe")

udmodel_latin <- udpipe_load_model(file = "../data/latin-perseus-ud-2.5-191206.udpipe")

udmodel_latin <- udpipe_load_model(file = "../data/latin-proiel-ud-2.5-191206.udpipe")

```

## Anotate the text using UDpipe
```{r}
udpipe_text <- as.data.frame(udpipe_annotate(udmodel_latin, x = EDCS$clean_text_interpretive_word))
str(udpipe_text)
```

## Overview of linguistic word categories
```{r}
table(udpipe_text$upos)
```

```{r}
nouns <- udpipe_text %>%
  filter(udpipe_text$upos == "NOUN")
```

```{r}
verbs <- udpipe_text %>%
  filter(udpipe_text$upos == "VERB")
```

```{r}
punctuation <- udpipe_text %>%
  filter(udpipe_text$upos == "PUNCT")
```

```{r}
problematic <- udpipe_text %>%
  filter(udpipe_text$upos == "X")
```

## The most frequent of all word lemmata
```{r}
udpipe_text %>%
  count(lemma, sort = TRUE) %>%
  filter(n > 1000) %>%
  mutate(lemma = reorder(lemma, n)) %>%
  print()
```

## The most frequent of nouns lemmata
```{r}
nouns %>%
  count(lemma, sort = TRUE) %>%
  filter(n > 1000) %>%
  mutate(lemma = reorder(lemma, n)) %>%
  print()
```

```{r}
verbs %>%
  count(lemma, sort = TRUE) %>%
  filter(n > 1000) %>%
  mutate(lemma = reorder(lemma, n)) %>%
  print()
```

```{r}
punctuation %>%
  count(lemma, sort = TRUE) %>%
  filter(n > 10) %>%
  mutate(lemma = reorder(lemma, n)) %>%
  print()
```


## Join the entire dataset with the NLP UD pipe output
```{r}



tail(udpipe_text)
udpipe_text <- udpipe_text %>%
  mutate(insc_id = (as.numeric(str_replace(doc_id, pattern = "doc", replacement = ""))))
EDCS$doc_id <- 1:nrow(EDCS)

full_appended <- left_join(EDCS, udpipe_text, by = c("doc_id" = "insc_id"))
```
```{r}
head(full_appended)
```


```{r}
save(full_appended, file="output/EDCS_lemmatized_2021-01-21.Rdata")
```

# Save to Sciencedata
```{r}
EDCS_lemmatized_json <- jsonlite::toJSON(full_appended, auto_unbox = TRUE)
mycred_secret<- readLines("~/mysecret.txt")
write(EDCS_lemmatized_json, file="output/EDCS_text_lemmatized_udpipe_2021-01-21.json")
request("output/EDCS_text_lemmatized_udpipe_2021-01-21.json", path="/sharingout/648597@au.dk/SDAM_root/SDAM_data/EDCS/",
        method="PUT", cred=c(mycred_secret[1], mycred_secret[2]))
```



# Remove local copy of the json and the credential before submitting to GitHub
```{r}
file.remove("./EDCS_text_lemmatized_udpipe_2020-12-22.json")
remove(mycred_secret)
```
