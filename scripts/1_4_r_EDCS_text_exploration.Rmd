---
title: "Text mining of lemmatized corpus"
author: "Petra Hermankova"
date: "26/01/2021"
output:
  html_document:
    theme: united
    toc: yes
    toc_float: true
    number_sections: true
    toc_depth: 2
    df_print: paged
---

```{r setup, include=FALSE, echo=FALSE}
require("knitr")
opts_knit$set(root.dir = "/home/petra/Github/EDCS_ETL/")

library(tidyverse)
library(jsonlite)
```

## Loading data
Load the dataset, if you have Sciencedata.dk credentials



Make a list and tibble from the downloaded dataset
```{r}
EDCS <- jsonlite::fromJSON("../output/EDCS_text_cleaned_2022-02-15.json")
```

# Text of inscription

## How many inscriptions contain a text of an inscription

```{r}
length(na.omit(EDCS$clean_text_interpretive_word))
```
In percent:
```{r}
length(na.omit(EDCS$clean_text_interpretive_word))/(nrow(EDCS)/100)
```

## How many words there are:

Original text before cleaning:
```{r}
sum(lengths(gregexpr("\\w+", EDCS$inscription)) + 1)

#different counting method
sum(na.omit(str_count(EDCS$inscription, '\\w+')))
```

Text after cleaning:
```{r}
sum(lengths(gregexpr("\\w+", EDCS$clean_text_interpretive_word)) + 1)

#different counting method
sum(na.omit(str_count(EDCS$clean_text_interpretive_word, '\\w+')))
```

Conservative text
```{r}
sum(lengths(gregexpr("\\w+", EDCS$clean_text_conservative)) + 1)

#different counting method
sum(na.omit(str_count(EDCS$clean_text_conservative, '\\w+')))
```


## The most common words

```{r}
library(dplyr)
library(tidytext)
```
### Original uncleaned dataset


```{r}
orig_words <- EDCS %>% 
  unnest_tokens(output = word, input = inscription) 

orig_wordcounts <- orig_words %>% count(word, sort = TRUE)

head(orig_wordcounts, 20)
```


### Conservative dataset

```{r}
cons_words <- EDCS %>% 
  unnest_tokens(output = word, input = clean_text_conservative) 

cons_wordcounts <- cons_words %>% count(word, sort = TRUE)

head(cons_wordcounts, 20)
```

### Interpretive dataset

```{r}
int_words <- EDCS %>% 
  unnest_tokens(output = word, input = clean_text_interpretive_word) 

int_wordcounts <- int_words %>% count(word, sort = TRUE)

head(int_wordcounts, 10)
```

### Random inscriptions

```{r}
EDCS_inscrtype<- EDCS %>% 
  filter(EDCS$inscr_type != "list()")

  
random100 <- sample_n(EDCS_inscrtype, 100)

EDCS_inscrtype_export <- EDCS_inscrtype %>%
  select(`EDCS-ID`, publication, province, province_list , place, place_list, Links, language, `dating from`, `dating to`, start_yr, end_yr_list, end_yr_1, notes_dating, status, status_list, inscr_type, status_notation, inscr_process, Latitude, Longitude, photo, Material, Comment, notes_references, notes_comments, inscription, inscription_stripped_final, clean_text_interpretive_word, clean_text_conservative, notes_dating, notes_references, notes_comments)


write_csv(x=EDCS_inscrtype_export, path="output/EDCS_random100_inscrtype.csv")
```





















### How many inscriptions contain Greek language

```{r}
greek<- EDCS %>% filter(language == grep(x = EDCS$language, "GR", value = TRUE))
```


```{r}
greek %>% 
  count(province, sort=T)
```

