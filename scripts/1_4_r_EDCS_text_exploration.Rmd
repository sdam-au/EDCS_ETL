---
title: "Text exploration of the EDCS corpus"
author:
- Petra Hermankova^[Aarhus University, petra.hermankova@cas.au.dk, https://orcid.org/0000-0002-6349-0540]
date: "`r format(Sys.time(), '%d %B, %Y')`"
output:
  html_document:
    theme: united
    toc: yes
    toc_float: true
    number_sections: true
    toc_depth: 2
    df_print: paged
---

```{r setup, include=FALSE, echo=FALSE}
require("knitr")
#opts_knit$set(root.dir = "/home/petra/Github/EDCS_ETL/")

library(tidyverse)
library(jsonlite)
```

## Loading data

Load the dataset from Sciencedata.dk
```{r}
EDCS <- jsonlite::fromJSON("https://sciencedata.dk/public/1f5f56d09903fe259c0906add8b3a55e/EDCS_text_cleaned_2022-02-15.json")
```

Or load local dataset
```{r}
getwd()
EDCS <- jsonlite::fromJSON("../data/EDCS_text_cleaned_2022-09-12.json")
```


# Dataset exploration
```{r}
names(EDCS)
```

# Text of inscription

## How many inscriptions contain a text of an inscription

```{r}
length(na.omit(EDCS$clean_text_interpretive_word))
```
In percent:
```{r}
length(na.omit(EDCS$clean_text_interpretive_word))/(nrow(EDCS)/100)
```

## How many words there are:

Original text before cleaning:
```{r}
sum(lengths(gregexpr("\\w+", EDCS$inscription)) + 1)

#different counting method
sum(na.omit(str_count(EDCS$inscription, '\\w+')))
```

Text after cleaning:
```{r}
sum(lengths(gregexpr("\\w+", EDCS$clean_text_interpretive_word)) + 1)

#different counting method
sum(na.omit(str_count(EDCS$clean_text_interpretive_word, '\\w+')))
```

Conservative text
```{r}
sum(lengths(gregexpr("\\w+", EDCS$clean_text_conservative)) + 1)

#different counting method
sum(na.omit(str_count(EDCS$clean_text_conservative, '\\w+')))
```


## The most common words

```{r}
library(dplyr)
library(tidytext)
```
### Original uncleaned dataset


```{r}
orig_words <- EDCS %>% 
  unnest_tokens(output = word, input = inscription) 

orig_wordcounts <- orig_words %>% count(word, sort = TRUE)

head(orig_wordcounts, 20)
```


### Conservative dataset

```{r}
cons_words <- EDCS %>% 
  unnest_tokens(output = word, input = clean_text_conservative) 

cons_wordcounts <- cons_words %>% count(word, sort = TRUE)

head(cons_wordcounts, 20)
```

### Interpretive dataset

```{r}
int_words <- EDCS %>% 
  unnest_tokens(output = word, input = clean_text_interpretive_word) 

int_wordcounts <- int_words %>% count(word, sort = TRUE)

head(int_wordcounts, 10)
```

### Tagging 100 random inscriptions 

With material:

```{r}
EDCS_inscrtype<- EDCS %>% 
  filter(EDCS$inscr_type != "list()")

EDCS_inscrtype_export_material <- EDCS_inscrtype %>%
  select(`EDCS-ID`, material, inscription, clean_text_interpretive_word, clean_text_conservative)

random100 <- sample_n(EDCS_inscrtype_export_material, 100)

write_csv(x=random100, file="../output/EDCS_random100_inscrtype_material.csv")
```

Without material: 

```{r}

EDCS_inscrtype_export_nomat <- EDCS_inscrtype %>%
  select(`EDCS-ID`, inscription, clean_text_interpretive_word, clean_text_conservative)

random100_2 <- sample_n(EDCS_inscrtype_export_nomat, 100)

write_csv(x=random100_2, file="../output/EDCS_random100_inscrtype_nomaterial.csv")
```


### Extracting unique labels for inscription types
```{r}
EDCS_types<- as.data.frame(unique(unlist(EDCS$inscr_type))) 

write_csv(x=EDCS_types,file="../output/EDCS_types_inscr.csv", col_names = FALSE)

```







### How many inscriptions contain Greek language

```{r}
greek<- EDCS %>% filter(language == grep(x = EDCS$language, "GR", value = TRUE))
```


```{r}
greek %>% 
  count(province, sort=T)
```

